{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b19025e-a6d4-4d25-a093-60a8900a642d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9573493-3d79-44d1-b7f5-6f4aaca779fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_bench = pd.read_pickle(\"Datasets/ProCon-bench/StanceBenchmarkProCon_allTrainingDatasets_nopreprocessing.pickle\")\n",
    "\n",
    "dev_df_bench = pd.read_pickle(\"Datasets/ProCon-bench/StanceBenchmarkProCon_allDevDatasets_nopreprocessing.pickle\")\n",
    "\n",
    "test_df_bench = pd.read_pickle(\"Datasets/ProCon-bench/StanceBenchmarkProCon_allTestDatasets_nopreprocessing.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1734a2b-1d13-490b-93a8-cb4f7c0e451f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arc_train_data = train_df_bench[\"arc_train\"]\n",
    "df_ibmcs_train_data = train_df_bench[\"ibmcs_train\"]\n",
    "df_perspectrum_train_data = train_df_bench[\"perspectrum_train\"]\n",
    "df_fnc1_train_data = train_df_bench[\"fnc1_train\"]\n",
    "df_iac1_train_data = train_df_bench[\"iac1_train\"]\n",
    "df_semeval2016t6_train_data = train_df_bench[\"semeval2016t6_train\"]\n",
    "df_semeval2019t7_train_data = train_df_bench[\"semeval2019t7_train\"]\n",
    "df_snopes_train_data = train_df_bench[\"snopes_train\"]\n",
    "df_argmin_train_data = train_df_bench[\"argmin_train\"]\n",
    "df_scd_train_data = train_df_bench[\"scd_train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "563c9fee-ab3f-4415-bcf0-d675ca604faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arc_dev_data = dev_df_bench[\"arc_dev\"]\n",
    "df_ibmcs_dev_data = dev_df_bench[\"ibmcs_dev\"]\n",
    "df_perspectrum_dev_data = dev_df_bench[\"perspectrum_dev\"]\n",
    "df_fnc1_dev_data = dev_df_bench[\"fnc1_dev\"]\n",
    "df_iac1_dev_data = dev_df_bench[\"iac1_dev\"]\n",
    "df_semeval2016t6_dev_data = dev_df_bench[\"semeval2016t6_dev\"]\n",
    "df_semeval2019t7_dev_data = dev_df_bench[\"semeval2019t7_dev\"]\n",
    "df_snopes_dev_data = dev_df_bench[\"snopes_dev\"]\n",
    "df_argmin_dev_data = dev_df_bench[\"argmin_dev\"]\n",
    "df_scd_dev_data = dev_df_bench[\"scd_dev\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6f08290-17b6-4a6d-a55a-9fedf0be2156",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arc_train_data[\"dataset\"] = \"arc_train\"\n",
    "train_df_bench[\"arc_train\"] =  df_arc_train_data\n",
    "\n",
    "df_ibmcs_train_data[\"dataset\"] = \"ibmcs_train\"\n",
    "train_df_bench[\"ibmcs_train\"] =  df_ibmcs_train_data\n",
    "\n",
    "df_perspectrum_train_data[\"dataset\"] = \"perspectrum_train\"\n",
    "train_df_bench[\"perspectrum_train\"] = df_perspectrum_train_data\n",
    "\n",
    "df_fnc1_train_data[\"dataset\"] = \"fnc1_train\"\n",
    "train_df_bench[\"fnc1_train\"] = df_fnc1_train_data\n",
    "\n",
    "df_iac1_train_data[\"dataset\"] = \"iac1_train\"\n",
    "train_df_bench[\"iac1_train\"] = df_iac1_train_data\n",
    "\n",
    "df_semeval2016t6_train_data[\"dataset\"] = \"semeval2016t6_train\"\n",
    "train_df_bench[\"semeval2016t6_train\"] = df_semeval2016t6_train_data\n",
    "\n",
    "df_semeval2019t7_train_data[\"dataset\"] = \"semeval2019t7_train\"\n",
    "train_df_bench[\"semeval2019t7_train\"] = df_semeval2019t7_train_data\n",
    "\n",
    "df_snopes_train_data[\"dataset\"] = \"snopes_train\"\n",
    "train_df_bench[\"snopes_train\"] = df_snopes_train_data\n",
    "\n",
    "\n",
    "df_argmin_train_data[\"dataset\"] = \"argmin_train\"\n",
    "train_df_bench[\"argmin_train\"] = df_argmin_train_data\n",
    "\n",
    "df_scd_train_data[\"dataset\"] = \"scd_train\"\n",
    "train_df_bench[\"scd_train\"] = df_scd_train_data\n",
    "\n",
    "\n",
    "train_df = pd.concat(train_df_bench.values())\n",
    "train_df = train_df[[\"dataset\", \"topic\", \"text\", \"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fc7db44-9cda-41bf-a8ba-46bbc1db015d",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_datasets_train = [df_arc_train_data, df_perspectrum_train_data, df_fnc1_train_data]\n",
    "list_datasets_train2 = [df_iac1_train_data, df_semeval2016t6_train_data, df_semeval2019t7_train_data]\n",
    "list_datasets_train3 = [df_snopes_train_data, df_argmin_train_data, df_scd_train_data, df_ibmcs_train_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac3038d6-80d5-455b-b424-874f4df033c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_datasets_dev = [df_arc_dev_data, df_perspectrum_dev_data, df_fnc1_dev_data]\n",
    "list_datasets_dev2 = [df_iac1_dev_data, df_semeval2016t6_dev_data, df_semeval2019t7_dev_data]\n",
    "list_datasets_dev3 =  [df_snopes_dev_data, df_argmin_dev_data, df_scd_dev_data, df_ibmcs_dev_data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75d11584-94a9-4fa3-af80-78ae7a7ed243",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_datasets_str = ['df_snopes_train_data', 'df_argmin_train_data', 'df_scd_train_data', 'df_ibmcs_train_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3dda290b-1164-49f9-b91c-cdae4f743d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_datasets_train_str = ['df_arc_train_data', 'df_perspectrum_train_data', 'df_fnc1_train_data']\n",
    "list_datasets_train2_str = ['df_iac1_train_data', 'df_semeval2016t6_train_data', 'df_semeval2019t7_train_data']\n",
    "list_datasets_train3_str = ['df_snopes_train_data', 'df_argmin_train_data', 'df_scd_train_data', 'df_ibmcs_train_data']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c403ce1-6252-4f66-91d8-00f2c0ada3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"sentence-transformers/nli-roberta-large\"\n",
    "\n",
    "def make_model(params=None):\n",
    "    return SetFitModel.from_pretrained(\n",
    "        model_id\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8128fb51-5932-40f4-8f5b-45ec255353bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.losses import CosineSimilarityLoss, ContrastiveLoss, BatchAllTripletLoss\n",
    "\n",
    "def hyperparameter_search_function(trial):\n",
    "    return {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\",1e-5, 1e-2),\n",
    "        \"loss_class\": trial.suggest_categorical(\"loss_class\", [CosineSimilarityLoss, ContrastiveLoss, BatchAllTripletLoss]),\n",
    "        \"num_epochs\": trial.suggest_int(\"num_epochs\", 2, 20),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edfe7571-6131-4841-82d0-d615b9a0f881",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d7f01ef4-b8e2-4974-8625-53cdbb7c0b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f8eefcc-9654-4ea3-add1-53cab369bc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
      "\u001b[32m[I 2023-06-05 15:04:28,144]\u001b[0m A new study created in memory with name: no-name-2528b9f0-d7f5-4a65-a6a3-8b56bd39d603\u001b[0m\n",
      "/home/user/.local/lib/python3.8/site-packages/optuna/distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'sentence_transformers.losses.CosineSimilarityLoss.CosineSimilarityLoss'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "/home/user/.local/lib/python3.8/site-packages/optuna/distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'sentence_transformers.losses.ContrastiveLoss.ContrastiveLoss'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "/home/user/.local/lib/python3.8/site-packages/optuna/distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'sentence_transformers.losses.BatchAllTripletLoss.BatchAllTripletLoss'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "Trial: {'learning_rate': 0.0015623001798501118, 'loss_class': <class 'sentence_transformers.losses.ContrastiveLoss.ContrastiveLoss'>, 'num_epochs': 19}\n",
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
      "Applying column mapping to training dataset\n",
      "Generating Training Pairs: 100%|██████████| 5/5 [00:02<00:00,  1.85it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 144160\n",
      "  Num epochs = 19\n",
      "  Total optimization steps = 1369520\n",
      "  Total train batch size = 2\n",
      "\u001b[33m[W 2023-06-05 15:04:34,828]\u001b[0m Trial 0 failed with parameters: {'learning_rate': 0.0015623001798501118, 'loss_class': <class 'sentence_transformers.losses.ContrastiveLoss.ContrastiveLoss'>, 'num_epochs': 19} because of the following error: AttributeError(\"'torch.device' object has no attribute '_apply'\").\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/setfit/integrations.py\", line 27, in _objective\n",
      "    trainer.train(trial=trial)\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/setfit/trainer.py\", line 395, in train\n",
      "    self.model.model_body.fit(\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/sentence_transformers/SentenceTransformer.py\", line 649, in fit\n",
      "    loss_model.to(self._target_device)\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1145, in to\n",
      "    return self._apply(convert)\n",
      "AttributeError: 'torch.device' object has no attribute '_apply'\n",
      "\u001b[33m[W 2023-06-05 15:04:34,833]\u001b[0m Trial 0 failed with value None.\u001b[0m\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'torch.device' object has no attribute '_apply'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 43\u001b[0m\n\u001b[1;32m     30\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train\u001b[38;5;241m.\u001b[39munique(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     32\u001b[0m trainer \u001b[38;5;241m=\u001b[39m SetFitTrainer(\n\u001b[1;32m     33\u001b[0m     model_init\u001b[38;5;241m=\u001b[39mmake_model,\n\u001b[1;32m     34\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m     column_mapping\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m     40\u001b[0m     )\n\u001b[0;32m---> 43\u001b[0m best \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhyperparameter_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhyperparameter_search_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m best\n\u001b[1;32m     46\u001b[0m settings[data_name] \u001b[38;5;241m=\u001b[39m best\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/setfit/trainer.py:523\u001b[0m, in \u001b[0;36mSetFitTrainer.hyperparameter_search\u001b[0;34m(self, hp_space, compute_objective, n_trials, direction, backend, hp_name, **kwargs)\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_objective \u001b[38;5;241m=\u001b[39m default_compute_objective \u001b[38;5;28;01mif\u001b[39;00m compute_objective \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m compute_objective\n\u001b[1;32m    520\u001b[0m backend_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    521\u001b[0m     HPSearchBackend\u001b[38;5;241m.\u001b[39mOPTUNA: run_hp_search_optuna,\n\u001b[1;32m    522\u001b[0m }\n\u001b[0;32m--> 523\u001b[0m best_run \u001b[38;5;241m=\u001b[39m \u001b[43mbackend_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhp_search_backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m best_run\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/setfit/integrations.py:37\u001b[0m, in \u001b[0;36mrun_hp_search_optuna\u001b[0;34m(trainer, n_trials, direction, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m n_jobs \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_jobs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     36\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39mdirection, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 37\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_objective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m best_trial \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_trial\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m BestRun(\u001b[38;5;28mstr\u001b[39m(best_trial\u001b[38;5;241m.\u001b[39mnumber), best_trial\u001b[38;5;241m.\u001b[39mvalue, best_trial\u001b[38;5;241m.\u001b[39mparams, study)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/optuna/study/study.py:425\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    323\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    330\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    332\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 425\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/setfit/integrations.py:27\u001b[0m, in \u001b[0;36mrun_hp_search_optuna.<locals>._objective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_objective\u001b[39m(trial):\n\u001b[1;32m     26\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m     \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m# If there hasn't been any evaluation during the training loop.\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(trainer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/setfit/trainer.py:395\u001b[0m, in \u001b[0;36mSetFitTrainer.train\u001b[0;34m(self, num_epochs, batch_size, learning_rate, body_learning_rate, l2_weight, max_length, trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    392\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Total train batch size = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    394\u001b[0m     warmup_steps \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39mceil(total_train_steps \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarmup_proportion)\n\u001b[0;32m--> 395\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_body\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_objectives\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loss\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarmup_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_amp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_amp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mhas_differentiable_head \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_freeze:\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;66;03m# Train the final classifier\u001b[39;00m\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m    407\u001b[0m         x_train,\n\u001b[1;32m    408\u001b[0m         y_train,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    415\u001b[0m         show_progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    416\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sentence_transformers/SentenceTransformer.py:649\u001b[0m, in \u001b[0;36mSentenceTransformer.fit\u001b[0;34m(self, train_objectives, evaluator, epochs, steps_per_epoch, scheduler, warmup_steps, optimizer_class, optimizer_params, weight_decay, evaluation_steps, output_path, save_best_model, max_grad_norm, use_amp, callback, show_progress_bar, checkpoint_path, checkpoint_save_steps, checkpoint_save_total_limit)\u001b[0m\n\u001b[1;32m    647\u001b[0m loss_models \u001b[38;5;241m=\u001b[39m [loss \u001b[38;5;28;01mfor\u001b[39;00m _, loss \u001b[38;5;129;01min\u001b[39;00m train_objectives]\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m loss_model \u001b[38;5;129;01min\u001b[39;00m loss_models:\n\u001b[0;32m--> 649\u001b[0m     \u001b[43mloss_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_target_device\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m9999999\u001b[39m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m steps_per_epoch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m steps_per_epoch \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m(convert)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'torch.device' object has no attribute '_apply'"
     ]
    }
   ],
   "source": [
    "### All the datasets:\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import setfit\n",
    "from setfit import SetFitModel, SetFitTrainer\n",
    "\n",
    "settings = defaultdict(str)\n",
    "\n",
    "# trainer = SetFitTrainer(\n",
    "#         model_init=make_model,\n",
    "#         train_dataset=train,\n",
    "#         eval_dataset=dev,\n",
    "#         num_epochs=1,\n",
    "#         batch_size=2,\n",
    "#         num_iterations=5,\n",
    "#         column_mapping={\"text\": \"text\", \"label\": \"label\"},\n",
    "#         )\n",
    "\n",
    "n = 0\n",
    "\n",
    "for data in zip(list_datasets_train3, list_datasets_dev3):\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    train = Dataset.from_pandas(data[0], split=\"train\")\n",
    "    dev = Dataset.from_pandas(data[1], split=\"dev\")\n",
    "    num_classes = len(train.unique(\"label\"))\n",
    "    \n",
    "    trainer = SetFitTrainer(\n",
    "        model_init=make_model,\n",
    "        train_dataset=train,\n",
    "        eval_dataset=dev,\n",
    "        num_epochs=1,\n",
    "        batch_size=2,\n",
    "        num_iterations=5,\n",
    "        column_mapping={\"text\": \"text\", \"label\": \"label\"},\n",
    "        )\n",
    "\n",
    "    \n",
    "    best = trainer.hyperparameter_search(hyperparameter_search_function, n_trials=10)\n",
    "    best\n",
    "    \n",
    "    settings[data_name] = best\n",
    "    #trainer.train(body_learning_rate=1e-5, num_epochs=1)\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394121b1-b711-4f58-b60a-09399ccf5d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.apply_hyperparameters(best.hyperparameters, final_model=True) # replaces model_init with a fixed model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f320c4d1-471d-489c-9f51-502ff880570f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704c3b2c-a020-4bec-bb58-8050ef722725",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #trainer.train(learning_rate=1e-2, num_epochs=50)\n",
    "    trainer.apply_hyperparameters(best.hyperparameters, final_model=True) # replaces model_init with a fixed model\n",
    "    trainer.train()\n",
    "    \n",
    "    result = trainer_set.evaluate()\n",
    "    best.objective, result\n",
    "    \n",
    "    results_f1[data_name] = result\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf6894a-040a-4141-a76c-d7dc615da06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = trainer.hyperparameter_search(hyperparameter_search_function, n_trials=10)\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2786a820-ff39-4a92-8089-9dd76d76f923",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.apply_hyperparameters(best.hyperparameters, final_model=True) # replaces model_init with a fixed model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0a57d3-1063-4e99-b1ac-8922b759f864",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = trainer.evaluate()\n",
    "best.objective, metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
